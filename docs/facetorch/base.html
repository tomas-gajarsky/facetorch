<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>facetorch.base API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}#lunr-search{width:100%;font-size:1em;padding:6px 9px 5px 9px;border:1px solid silver}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>facetorch.base</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import os
from abc import ABCMeta, abstractmethod
from typing import Optional, Tuple, Union

import torch
from codetiming import Timer
from torchvision import transforms

from facetorch import utils
from facetorch.datastruct import ImageData
from facetorch.logger import LoggerJsonFile
from facetorch.transforms import script_transform

logger = LoggerJsonFile().logger


class BaseProcessor(object, metaclass=ABCMeta):
    @Timer(&#34;BaseProcessor.__init__&#34;, &#34;{name}: {milliseconds:.2f} ms&#34;, logger.debug)
    def __init__(
        self,
        transform: Optional[transforms.Compose],
        device: torch.device,
        optimize_transform: bool,
    ):
        &#34;&#34;&#34;Base class for processors.

        All data pre and post processors should subclass it.
        All subclass should overwrite:

        - Methods:``run``, used for running the processing functionality.

        Args:
            device (torch.device): Torch device cpu or cuda.
            transform (transforms.Compose): Transform compose object to be applied to the image.
            optimize_transform (bool): Whether to optimize the transform.

        &#34;&#34;&#34;
        super().__init__()
        self.device = device
        self.transform = transform if transform != &#34;None&#34; else None
        self.optimize_transform = optimize_transform

        if self.transform is not None:
            self.transform = utils.fix_transform_list_attr(self.transform)

        if self.optimize_transform is True:
            self.optimize()

    def optimize(self):
        &#34;&#34;&#34;Optimizes the transform using torch.jit and deploys it to the device.&#34;&#34;&#34;
        if self.transform is not None:
            self.transform = script_transform(self.transform)
            self.transform = self.transform.to(self.device)

    @abstractmethod
    def run(self):
        &#34;&#34;&#34;Abstract method that should implement a tensor processing functionality&#34;&#34;&#34;


class BaseReader(BaseProcessor):
    @Timer(&#34;BaseReader.__init__&#34;, &#34;{name}: {milliseconds:.2f} ms&#34;, logger.debug)
    def __init__(
        self,
        transform: transforms.Compose,
        device: torch.device,
        optimize_transform: bool,
    ):
        &#34;&#34;&#34;Base class for image reader.

        All image readers should subclass it.
        All subclass should overwrite:

        - Methods:``run``, used for running the reading process and return a tensor.

        Args:
            transform (transforms.Compose): Transform to be applied to the image.
            device (torch.device): Torch device cpu or cuda.
            optimize_transform (bool): Whether to optimize the transforms that are resizing
            the image to a fixed size.

        &#34;&#34;&#34;
        super().__init__(transform, device, optimize_transform)
        self.device = device
        self.optimize_transform = optimize_transform

    @abstractmethod
    def run(self, path: str) -&gt; ImageData:
        &#34;&#34;&#34;Abstract method that reads an image from a path and returns a data object containing
        a tensor of the image with
         shape (batch, channels, height, width).

        Args:
            path (str): Path to the image.

        Returns:
            ImageData: ImageData object with the image tensor.
        &#34;&#34;&#34;


class BaseDownloader(object, metaclass=ABCMeta):
    @Timer(&#34;BaseDownloader.__init__&#34;, &#34;{name}: {milliseconds:.2f} ms&#34;, logger.debug)
    def __init__(
        self,
        file_id: str,
        path_local: str,
    ):
        &#34;&#34;&#34;Base class for downloaders.

        All downloaders should subclass it.
        All subclass should overwrite:

        - Methods:``run``, supporting to run the download functionality.

        Args:
            file_id (str): ID of the hosted file (e.g. Google Drive File ID).
            path_local (str): The file is downloaded to this local path.

        &#34;&#34;&#34;
        super().__init__()
        self.file_id = file_id
        self.path_local = path_local

    @abstractmethod
    def run(self) -&gt; None:
        &#34;&#34;&#34;Abstract method that should implement the download functionality&#34;&#34;&#34;


class BaseModel(object, metaclass=ABCMeta):
    @Timer(&#34;BaseModel.__init__&#34;, &#34;{name}: {milliseconds:.2f} ms&#34;, logger.debug)
    def __init__(self, downloader: BaseDownloader, device: torch.device):
        &#34;&#34;&#34;Base class for torch models.

        All detectors and predictors should subclass it.
        All subclass should overwrite:

        - Methods:``run``, supporting to make detections and predictions with the model.

        Args:
            downloader (BaseDownloader): Downloader for the model.
            device (torch.device): Torch device cpu or cuda.

        Attributes:
            model (torch.jit.ScriptModule or torch.jit.TracedModule): Loaded TorchScript model.

        &#34;&#34;&#34;
        super().__init__()
        self.downloader = downloader
        self.path_local = self.downloader.path_local
        self.device = device

        self.model = self.load_model()

    @Timer(&#34;BaseModel.load_model&#34;, &#34;{name}: {milliseconds:.2f} ms&#34;, logger.debug)
    def load_model(self) -&gt; Union[torch.jit.ScriptModule, torch.jit.TracedModule]:
        &#34;&#34;&#34;Loads the TorchScript model.

        Returns:
            Union[torch.jit.ScriptModule, torch.jit.TracedModule]: Loaded TorchScript model.
        &#34;&#34;&#34;
        if not os.path.exists(self.path_local):
            dir_local = os.path.dirname(self.path_local)
            os.makedirs(dir_local, exist_ok=True)
            self.downloader.run()
        model = torch.jit.load(self.path_local, map_location=self.device)
        model.eval()

        return model

    @Timer(&#34;BaseModel.inference&#34;, &#34;{name}: {milliseconds:.2f} ms&#34;, logger.debug)
    def inference(
        self, tensor: torch.Tensor
    ) -&gt; Union[torch.Tensor, Tuple[torch.Tensor]]:
        &#34;&#34;&#34;Inference the model with the given tensor.

        Args:
            tensor (torch.Tensor): Input tensor for the model.

        Returns:
            Union[torch.Tensor, Tuple[torch.Tensor]]: Output tensor or tuple of tensors.
        &#34;&#34;&#34;
        with torch.no_grad():

            if tensor.device != self.device:
                tensor = tensor.to(self.device)

            logits = self.model(tensor)

        return logits

    @abstractmethod
    def run(self):
        &#34;&#34;&#34;Abstract method for making the predictions. Example pipeline:

        - self.preprocessor.run
        - self.inference
        - self.postprocessor.run

        &#34;&#34;&#34;</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="facetorch.base.BaseProcessor"><code class="flex name class">
<span>class <span class="ident">BaseProcessor</span></span>
<span>(</span><span>transform:Â Optional[torchvision.transforms.transforms.Compose], device:Â torch.device, optimize_transform:Â bool)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for processors.</p>
<p>All data pre and post processors should subclass it.
All subclass should overwrite:</p>
<ul>
<li>Methods:<code>run</code>, used for running the processing functionality.</li>
</ul>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>device</code></strong> :&ensp;<code>torch.device</code></dt>
<dd>Torch device cpu or cuda.</dd>
<dt><strong><code>transform</code></strong> :&ensp;<code>transforms.Compose</code></dt>
<dd>Transform compose object to be applied to the image.</dd>
<dt><strong><code>optimize_transform</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether to optimize the transform.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BaseProcessor(object, metaclass=ABCMeta):
    @Timer(&#34;BaseProcessor.__init__&#34;, &#34;{name}: {milliseconds:.2f} ms&#34;, logger.debug)
    def __init__(
        self,
        transform: Optional[transforms.Compose],
        device: torch.device,
        optimize_transform: bool,
    ):
        &#34;&#34;&#34;Base class for processors.

        All data pre and post processors should subclass it.
        All subclass should overwrite:

        - Methods:``run``, used for running the processing functionality.

        Args:
            device (torch.device): Torch device cpu or cuda.
            transform (transforms.Compose): Transform compose object to be applied to the image.
            optimize_transform (bool): Whether to optimize the transform.

        &#34;&#34;&#34;
        super().__init__()
        self.device = device
        self.transform = transform if transform != &#34;None&#34; else None
        self.optimize_transform = optimize_transform

        if self.transform is not None:
            self.transform = utils.fix_transform_list_attr(self.transform)

        if self.optimize_transform is True:
            self.optimize()

    def optimize(self):
        &#34;&#34;&#34;Optimizes the transform using torch.jit and deploys it to the device.&#34;&#34;&#34;
        if self.transform is not None:
            self.transform = script_transform(self.transform)
            self.transform = self.transform.to(self.device)

    @abstractmethod
    def run(self):
        &#34;&#34;&#34;Abstract method that should implement a tensor processing functionality&#34;&#34;&#34;</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="facetorch.analyzer.detector.post.BaseDetPostProcessor" href="analyzer/detector/post.html#facetorch.analyzer.detector.post.BaseDetPostProcessor">BaseDetPostProcessor</a></li>
<li><a title="facetorch.analyzer.detector.pre.BaseDetPreProcessor" href="analyzer/detector/pre.html#facetorch.analyzer.detector.pre.BaseDetPreProcessor">BaseDetPreProcessor</a></li>
<li><a title="facetorch.analyzer.predictor.post.BasePredPostProcessor" href="analyzer/predictor/post.html#facetorch.analyzer.predictor.post.BasePredPostProcessor">BasePredPostProcessor</a></li>
<li><a title="facetorch.analyzer.predictor.pre.BasePredPreProcessor" href="analyzer/predictor/pre.html#facetorch.analyzer.predictor.pre.BasePredPreProcessor">BasePredPreProcessor</a></li>
<li><a title="facetorch.analyzer.unifier.core.FaceUnifier" href="analyzer/unifier/core.html#facetorch.analyzer.unifier.core.FaceUnifier">FaceUnifier</a></li>
<li><a title="facetorch.base.BaseReader" href="#facetorch.base.BaseReader">BaseReader</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="facetorch.base.BaseProcessor.optimize"><code class="name flex">
<span>def <span class="ident">optimize</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Optimizes the transform using torch.jit and deploys it to the device.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def optimize(self):
    &#34;&#34;&#34;Optimizes the transform using torch.jit and deploys it to the device.&#34;&#34;&#34;
    if self.transform is not None:
        self.transform = script_transform(self.transform)
        self.transform = self.transform.to(self.device)</code></pre>
</details>
</dd>
<dt id="facetorch.base.BaseProcessor.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Abstract method that should implement a tensor processing functionality</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def run(self):
    &#34;&#34;&#34;Abstract method that should implement a tensor processing functionality&#34;&#34;&#34;</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="facetorch.base.BaseReader"><code class="flex name class">
<span>class <span class="ident">BaseReader</span></span>
<span>(</span><span>transform:Â torchvision.transforms.transforms.Compose, device:Â torch.device, optimize_transform:Â bool)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for image reader.</p>
<p>All image readers should subclass it.
All subclass should overwrite:</p>
<ul>
<li>Methods:<code>run</code>, used for running the reading process and return a tensor.</li>
</ul>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>transform</code></strong> :&ensp;<code>transforms.Compose</code></dt>
<dd>Transform to be applied to the image.</dd>
<dt><strong><code>device</code></strong> :&ensp;<code>torch.device</code></dt>
<dd>Torch device cpu or cuda.</dd>
<dt><strong><code>optimize_transform</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether to optimize the transforms that are resizing</dd>
</dl>
<p>the image to a fixed size.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BaseReader(BaseProcessor):
    @Timer(&#34;BaseReader.__init__&#34;, &#34;{name}: {milliseconds:.2f} ms&#34;, logger.debug)
    def __init__(
        self,
        transform: transforms.Compose,
        device: torch.device,
        optimize_transform: bool,
    ):
        &#34;&#34;&#34;Base class for image reader.

        All image readers should subclass it.
        All subclass should overwrite:

        - Methods:``run``, used for running the reading process and return a tensor.

        Args:
            transform (transforms.Compose): Transform to be applied to the image.
            device (torch.device): Torch device cpu or cuda.
            optimize_transform (bool): Whether to optimize the transforms that are resizing
            the image to a fixed size.

        &#34;&#34;&#34;
        super().__init__(transform, device, optimize_transform)
        self.device = device
        self.optimize_transform = optimize_transform

    @abstractmethod
    def run(self, path: str) -&gt; ImageData:
        &#34;&#34;&#34;Abstract method that reads an image from a path and returns a data object containing
        a tensor of the image with
         shape (batch, channels, height, width).

        Args:
            path (str): Path to the image.

        Returns:
            ImageData: ImageData object with the image tensor.
        &#34;&#34;&#34;</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="facetorch.base.BaseProcessor" href="#facetorch.base.BaseProcessor">BaseProcessor</a></li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="facetorch.analyzer.reader.core.ImageReader" href="analyzer/reader/core.html#facetorch.analyzer.reader.core.ImageReader">ImageReader</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="facetorch.base.BaseReader.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self, path:Â str) â€‘>Â <a title="facetorch.datastruct.ImageData" href="datastruct.html#facetorch.datastruct.ImageData">ImageData</a></span>
</code></dt>
<dd>
<div class="desc"><p>Abstract method that reads an image from a path and returns a data object containing
a tensor of the image with
shape (batch, channels, height, width).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>path</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the image.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>ImageData</code></dt>
<dd>ImageData object with the image tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def run(self, path: str) -&gt; ImageData:
    &#34;&#34;&#34;Abstract method that reads an image from a path and returns a data object containing
    a tensor of the image with
     shape (batch, channels, height, width).

    Args:
        path (str): Path to the image.

    Returns:
        ImageData: ImageData object with the image tensor.
    &#34;&#34;&#34;</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="facetorch.base.BaseProcessor" href="#facetorch.base.BaseProcessor">BaseProcessor</a></b></code>:
<ul class="hlist">
<li><code><a title="facetorch.base.BaseProcessor.optimize" href="#facetorch.base.BaseProcessor.optimize">optimize</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="facetorch.base.BaseDownloader"><code class="flex name class">
<span>class <span class="ident">BaseDownloader</span></span>
<span>(</span><span>file_id:Â str, path_local:Â str)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for downloaders.</p>
<p>All downloaders should subclass it.
All subclass should overwrite:</p>
<ul>
<li>Methods:<code>run</code>, supporting to run the download functionality.</li>
</ul>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>file_id</code></strong> :&ensp;<code>str</code></dt>
<dd>ID of the hosted file (e.g. Google Drive File ID).</dd>
<dt><strong><code>path_local</code></strong> :&ensp;<code>str</code></dt>
<dd>The file is downloaded to this local path.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BaseDownloader(object, metaclass=ABCMeta):
    @Timer(&#34;BaseDownloader.__init__&#34;, &#34;{name}: {milliseconds:.2f} ms&#34;, logger.debug)
    def __init__(
        self,
        file_id: str,
        path_local: str,
    ):
        &#34;&#34;&#34;Base class for downloaders.

        All downloaders should subclass it.
        All subclass should overwrite:

        - Methods:``run``, supporting to run the download functionality.

        Args:
            file_id (str): ID of the hosted file (e.g. Google Drive File ID).
            path_local (str): The file is downloaded to this local path.

        &#34;&#34;&#34;
        super().__init__()
        self.file_id = file_id
        self.path_local = path_local

    @abstractmethod
    def run(self) -&gt; None:
        &#34;&#34;&#34;Abstract method that should implement the download functionality&#34;&#34;&#34;</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="facetorch.downloader.DownloaderGDrive" href="downloader.html#facetorch.downloader.DownloaderGDrive">DownloaderGDrive</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="facetorch.base.BaseDownloader.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Abstract method that should implement the download functionality</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def run(self) -&gt; None:
    &#34;&#34;&#34;Abstract method that should implement the download functionality&#34;&#34;&#34;</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="facetorch.base.BaseModel"><code class="flex name class">
<span>class <span class="ident">BaseModel</span></span>
<span>(</span><span>downloader:Â <a title="facetorch.base.BaseDownloader" href="#facetorch.base.BaseDownloader">BaseDownloader</a>, device:Â torch.device)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for torch models.</p>
<p>All detectors and predictors should subclass it.
All subclass should overwrite:</p>
<ul>
<li>Methods:<code>run</code>, supporting to make detections and predictions with the model.</li>
</ul>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>downloader</code></strong> :&ensp;<code><a title="facetorch.base.BaseDownloader" href="#facetorch.base.BaseDownloader">BaseDownloader</a></code></dt>
<dd>Downloader for the model.</dd>
<dt><strong><code>device</code></strong> :&ensp;<code>torch.device</code></dt>
<dd>Torch device cpu or cuda.</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>torch.jit.ScriptModule</code> or <code>torch.jit.TracedModule</code></dt>
<dd>Loaded TorchScript model.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BaseModel(object, metaclass=ABCMeta):
    @Timer(&#34;BaseModel.__init__&#34;, &#34;{name}: {milliseconds:.2f} ms&#34;, logger.debug)
    def __init__(self, downloader: BaseDownloader, device: torch.device):
        &#34;&#34;&#34;Base class for torch models.

        All detectors and predictors should subclass it.
        All subclass should overwrite:

        - Methods:``run``, supporting to make detections and predictions with the model.

        Args:
            downloader (BaseDownloader): Downloader for the model.
            device (torch.device): Torch device cpu or cuda.

        Attributes:
            model (torch.jit.ScriptModule or torch.jit.TracedModule): Loaded TorchScript model.

        &#34;&#34;&#34;
        super().__init__()
        self.downloader = downloader
        self.path_local = self.downloader.path_local
        self.device = device

        self.model = self.load_model()

    @Timer(&#34;BaseModel.load_model&#34;, &#34;{name}: {milliseconds:.2f} ms&#34;, logger.debug)
    def load_model(self) -&gt; Union[torch.jit.ScriptModule, torch.jit.TracedModule]:
        &#34;&#34;&#34;Loads the TorchScript model.

        Returns:
            Union[torch.jit.ScriptModule, torch.jit.TracedModule]: Loaded TorchScript model.
        &#34;&#34;&#34;
        if not os.path.exists(self.path_local):
            dir_local = os.path.dirname(self.path_local)
            os.makedirs(dir_local, exist_ok=True)
            self.downloader.run()
        model = torch.jit.load(self.path_local, map_location=self.device)
        model.eval()

        return model

    @Timer(&#34;BaseModel.inference&#34;, &#34;{name}: {milliseconds:.2f} ms&#34;, logger.debug)
    def inference(
        self, tensor: torch.Tensor
    ) -&gt; Union[torch.Tensor, Tuple[torch.Tensor]]:
        &#34;&#34;&#34;Inference the model with the given tensor.

        Args:
            tensor (torch.Tensor): Input tensor for the model.

        Returns:
            Union[torch.Tensor, Tuple[torch.Tensor]]: Output tensor or tuple of tensors.
        &#34;&#34;&#34;
        with torch.no_grad():

            if tensor.device != self.device:
                tensor = tensor.to(self.device)

            logits = self.model(tensor)

        return logits

    @abstractmethod
    def run(self):
        &#34;&#34;&#34;Abstract method for making the predictions. Example pipeline:

        - self.preprocessor.run
        - self.inference
        - self.postprocessor.run

        &#34;&#34;&#34;</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="facetorch.analyzer.detector.core.FaceDetector" href="analyzer/detector/core.html#facetorch.analyzer.detector.core.FaceDetector">FaceDetector</a></li>
<li><a title="facetorch.analyzer.predictor.core.FacePredictor" href="analyzer/predictor/core.html#facetorch.analyzer.predictor.core.FacePredictor">FacePredictor</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="facetorch.base.BaseModel.load_model"><code class="name flex">
<span>def <span class="ident">load_model</span></span>(<span>self) â€‘>Â Union[torch.jit._script.ScriptModule,Â torch.jit._trace.TracedModule]</span>
</code></dt>
<dd>
<div class="desc"><p>Loads the TorchScript model.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Union[torch.jit.ScriptModule, torch.jit.TracedModule]</code></dt>
<dd>Loaded TorchScript model.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@Timer(&#34;BaseModel.load_model&#34;, &#34;{name}: {milliseconds:.2f} ms&#34;, logger.debug)
def load_model(self) -&gt; Union[torch.jit.ScriptModule, torch.jit.TracedModule]:
    &#34;&#34;&#34;Loads the TorchScript model.

    Returns:
        Union[torch.jit.ScriptModule, torch.jit.TracedModule]: Loaded TorchScript model.
    &#34;&#34;&#34;
    if not os.path.exists(self.path_local):
        dir_local = os.path.dirname(self.path_local)
        os.makedirs(dir_local, exist_ok=True)
        self.downloader.run()
    model = torch.jit.load(self.path_local, map_location=self.device)
    model.eval()

    return model</code></pre>
</details>
</dd>
<dt id="facetorch.base.BaseModel.inference"><code class="name flex">
<span>def <span class="ident">inference</span></span>(<span>self, tensor:Â torch.Tensor) â€‘>Â Union[torch.Tensor,Â Tuple[torch.Tensor]]</span>
</code></dt>
<dd>
<div class="desc"><p>Inference the model with the given tensor.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>tensor</code></strong> :&ensp;<code>torch.Tensor</code></dt>
<dd>Input tensor for the model.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Union[torch.Tensor, Tuple[torch.Tensor]]</code></dt>
<dd>Output tensor or tuple of tensors.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@Timer(&#34;BaseModel.inference&#34;, &#34;{name}: {milliseconds:.2f} ms&#34;, logger.debug)
def inference(
    self, tensor: torch.Tensor
) -&gt; Union[torch.Tensor, Tuple[torch.Tensor]]:
    &#34;&#34;&#34;Inference the model with the given tensor.

    Args:
        tensor (torch.Tensor): Input tensor for the model.

    Returns:
        Union[torch.Tensor, Tuple[torch.Tensor]]: Output tensor or tuple of tensors.
    &#34;&#34;&#34;
    with torch.no_grad():

        if tensor.device != self.device:
            tensor = tensor.to(self.device)

        logits = self.model(tensor)

    return logits</code></pre>
</details>
</dd>
<dt id="facetorch.base.BaseModel.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Abstract method for making the predictions. Example pipeline:</p>
<ul>
<li>self.preprocessor.run</li>
<li>self.inference</li>
<li>self.postprocessor.run</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def run(self):
    &#34;&#34;&#34;Abstract method for making the predictions. Example pipeline:

    - self.preprocessor.run
    - self.inference
    - self.postprocessor.run

    &#34;&#34;&#34;</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<form>
<input id="lunr-search" name="q" placeholder="ðŸ”Ž Search ..." aria-label="Search"
disabled minlength="2">
</form>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.css" integrity="sha512-j1u8eUJ4f23xPPxwOrLUPQaCD2dwzNqqmDDcWS4deWsMv2ohLqmXXuP3hU7g8TyzbMSakP/mMqoNBYWj8AEIFg==" crossorigin>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.js" integrity="sha512-plGUER9JkeEWPPqQBE4sdLqBoQug5Ap+BCGMc7bJ8BXkm+VVj6QzkpBz5Yv2yPkkq+cqg9IpkBaGCas6uDbW8g==" crossorigin></script>
<style>
.modal-dialog iframe {
width: 100vw;
height: calc(100vh - 80px);
}
@media screen and (min-width: 700px) {
.modal-dialog iframe {
width: 70vw;
height: 80vh;
}
}
.modal-dialog .tingle-modal-box {width: auto;}
.modal-dialog .tingle-modal-box__content {padding: 0;}
</style>
<script>
const input = document.getElementById('lunr-search');
input.disabled = false;
input.form.addEventListener('submit', (ev) => {
ev.preventDefault();
const url = new URL(window.location);
url.searchParams.set('q', input.value);
history.replaceState({}, null, url.toString());
search(input.value);
});
const query = new URL(window.location).searchParams.get('q');
if (query)
search(query);
function search(query) {
const url = '../doc-search.html#' + encodeURIComponent(query);
new tingle.modal({
cssClass: ['modal-dialog'],
onClose: () => {
const url = new URL(window.location);
url.searchParams.delete('q');
history.replaceState({}, null, url.toString());
setTimeout(() => input.focus(), 100);
}
}).setContent('<iframe src="' + url + '"></iframe>').open();
}
</script>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="facetorch" href="index.html">facetorch</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="facetorch.base.BaseProcessor" href="#facetorch.base.BaseProcessor">BaseProcessor</a></code></h4>
<ul class="">
<li><code><a title="facetorch.base.BaseProcessor.optimize" href="#facetorch.base.BaseProcessor.optimize">optimize</a></code></li>
<li><code><a title="facetorch.base.BaseProcessor.run" href="#facetorch.base.BaseProcessor.run">run</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="facetorch.base.BaseReader" href="#facetorch.base.BaseReader">BaseReader</a></code></h4>
<ul class="">
<li><code><a title="facetorch.base.BaseReader.run" href="#facetorch.base.BaseReader.run">run</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="facetorch.base.BaseDownloader" href="#facetorch.base.BaseDownloader">BaseDownloader</a></code></h4>
<ul class="">
<li><code><a title="facetorch.base.BaseDownloader.run" href="#facetorch.base.BaseDownloader.run">run</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="facetorch.base.BaseModel" href="#facetorch.base.BaseModel">BaseModel</a></code></h4>
<ul class="">
<li><code><a title="facetorch.base.BaseModel.load_model" href="#facetorch.base.BaseModel.load_model">load_model</a></code></li>
<li><code><a title="facetorch.base.BaseModel.inference" href="#facetorch.base.BaseModel.inference">inference</a></code></li>
<li><code><a title="facetorch.base.BaseModel.run" href="#facetorch.base.BaseModel.run">run</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>